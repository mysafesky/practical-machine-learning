predict(fit,newdata,interval="predict")
newdata = data.frame(x = mean(x))
predict(fit,newdata,interval="predict")
predict(fit,newdata,interval="confident")
predict(fit,newdata,interval="confidence")
rm(fit)
rm(diamond)
rm(newdata)
rm(sumC)
rm(sumCoef)
fit_1(y~x)
fit_1<-lm(y~x)
y_real <- y
y_m1 <- fit_1$coef[1]+fit_1$coef[2]*x
y_m2 <- mean(y)
(y_real-y_m1)^2
sum(y_real-y_m1)^2
sum((y_real-y_m1)^2)
sum((y_real-y_m2)^2)
sum((y_real-y_m1)^2)/ sum((y_real-y_m2)^2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names <- c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")
?train
trainFit <- train(diagnosis ~.,data = training(names),method = "glm")
trainFit <- train(diagnosis ~.,data = training[names],method = "glm")
class(training[names])
dim(training[names])
set.seed(1)
rpois(5, 2)
?dpois
?summaryRprof()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x = training[,c('Cement',
'BlastFurnaceSlag',
'FlyAsh',
'Water',
'Superplasticizer',
'CoarseAggregate',
'FineAggregate', 'Age')],
y = training$CompressiveStrength )
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_variables <- grep("^IL", names(training), value = TRUE)
preProc <- preProcess(training[, IL_variables], method = "pca", thresh = 0.9)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
train()
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("caret")
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("kernlab")
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
?train
install.packages("caret")
?train
??train
??train
?train
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
install.packages('e1071', dependencies=TRUE)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
+                   preProcess = "pca",
+                   trControl = trainControl(preProcOptions = list(thresh = 0.8)))
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain, ]
testing = mixtures[-inTrain, ]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
View(training)
?rexp
lambda = 0.2
rexp(1000,0.2)
x<-rexp(1000,0.2)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
library(knitr)
data(mtcars)
?mtcars
library(stats)
require(stats)
require(graphics)
?mtcars
pairs(mtcars, main = "mtcars data")
coplot(mpg ~ disp | as.factor(cyl), data = mtcars,
panel = panel.smooth, rows = 1)
pairs(mtcars, main = "mtcars data")
pairs(mtcars,panel=panel.smooth,main="MTCARS Pairing Plot")
?mtcars
summary(lm(mpg ~. ,data = mtcars))
summary(lm(mpg ~ am, data = mtcars))$coefficients
?lm
?mtcars
??corelation
?rcor
?cor
?mtcars
sstep(lm(mpg ~ ., data = mtcars))
step(lm(mpg ~ ., data = mtcars))
am_model <- lm(mpg ~ am, data = mtcars)
amNqsec_model <- lm(mpg ~ am + qsec, data = mtcars)
compare <- anova(am_model,amNqsec_model)
compare$Pr
t_test <- t.test(mpg ~ am, data = mtcars)
t_test
am_model <- lm(mpg ~ am, data = mtcars)
amNqsec_model <- lm(mpg ~ am + qsec, data = mtcars)
compare <- anova(amNqsec_model,am_model)
compare$Pr
?anova
am_model <- lm(mpg ~ am, data = mtcars)
amNqsec_model <- lm(mpg ~ am + qsec+wt, data = mtcars)
compare <- anova(amNqsec_model,am_model)
compare$Pr
t_test <- t.test(mpg ~ am, data = mtcars)
compare
amNqsec_model
?lm
anova(amNqsec_model)
new_model <- step(lm(mpg ~.,data = mtcars))
new_model$coeff
new_model <- step(lm(mpg ~ ., data = mtcars), trace = 0)
new_model$coeff
summary(new_modelel)
summary(new_model)
boxplot(mpg ~ am, data = mtcars,xlab = "Transmission type", ylab = "MPG",main = "MPG vs Transmission", names = c("Automatic", "Manual"))
summary(am_model)
fit1 <- lm(mpg ~ am, data = mtcars)
summary(am_model)$Coefficients
summary(am_model)$coefficients
?set.seed
library(ggplot2)
set.seed(1234)
n <- 40
lamba <- 0.2
sim_itr <- 1000
?matrix
rexp(n*sim_iter, lambda)
rexp(n*sim_itr, lambda)
library(ggplot2)
set.seed(1234)
n <- 40
lambda <- 0.2
sim_itr <- 1000
rexp(n*sim_itr, lambda)
x <- rexp(n*sim_itr, lambda)
?vector
sim_mean = vector(sim_itr)
sim_sd = vector(sim_itr)
for (i in 1:sim_itr)
{
sim_result <- rexp(n,lambda)
sim_mean(i) <- mean(sim_result)
sim_sd(i) <- sd(sim_result)
}
sim_mean = vector(sim_itr)
sim_sd = vector(sim_itr)
sim_mean = vector(length = sim_itr)
sim_sd = vector(length = sim_itr)
for (i in 1:sim_itr)
{
sim_result <- rexp(n,lambda)
sim_mean(i) <- mean(sim_result)
sim_sd(i) <- sd(sim_result)
}
for (i in 1:sim_itr)
{
sim_result <- rexp(n,lambda)
sim_mean[i] <- mean(sim_result)
sim_sd[i] <- sd(sim_result)
}
?ggplot
ggplot(data = sim_mean, geom = geom_histogram())
ggplot(data = data.frame(sim_mean), geom = geom_histogram())
ggplot(data = data.frame(sim_mean), geom = geom_histogram())
d <- ggplot(data = data.frame(sim_mean),aes(x=sim_mean))
d <- d + geom_histogram()
d <- ggplot(data = data.frame(sim_mean),aes(x=sim_mean))
d <- d + geom_histogram(binwidth = lambda,fill="red",color="black",aes(y = ..density..))
d
d <- ggplot(data = data.frame(sim_mean),aes(x=sim_mean))
d <- d + geom_histogram()
d
d <- ggplot(data = data.frame(sim_mean),aes(x=sim_mean))
d <- d + geom_histogram(aes(y = ..density..))
d <- d + stat_function(fun=dnorm,args=list(mean=theo_mean, sd=theo_sd),color = "red")
d <- d + labs(x = "Avgs of 40 distributions", y = "Density")
d
c_mean = [theo_mean,exp_mean]
c_mean = c(theo_mean,exp_mean)
?matrix
exp_mean = mean(sim_mean)
exp_sd = sd(sim_mean)
exp_var = var(sim_mean)
theo_mean = 1/lambda
theo_sd = ((1/lambda) * (1/sqrt(n)))
theo_var = theo_sd^2
comp = c(theo_mean,exp_mean,theo_sd,exp_sd,theo_var,exp_var)
comp_m = matrix(comp,nrow = 2)
colnames(comp_m) <- (" ","Theory","Simulation")
colnames(comp_m) <- c("Mean","Standard Derivation","variance")
library(qqplot2)
data(ToothGrowth)
library(qqplot2)
require(ToothGrowth)
install.packages("ToothGrouth")
install.packages(c("BH", "car", "knitr"))
require(ToothGrowth)
?ToothGrowth
library(qqplot2)
data(ToothGrowth)
data(ToothGrowth)
pairs(ToothGrowth,panel=panel.smooth,main="ToothGrowth Pairing Plot")
?pairs
library(GGally)
install.packages("GGally")
library(GGally)
?ggpairs
ggpairs(ToothGrowth, diag=list(continuous="density", discrete="bar"), axisLabels="show")
?ggpairs
custom_car <- ggpairs(mtcars[,c("mpg","wt","cyl")], upper = "blank", title = "Custom Example")
custom_car
pm <- ggpairs(
tips[,1:4],
upper = list(continuous = "density", combo = "box"),
lower = list(continuous = "points", combo = "dot")
)
data(tips, package = "reshape")
pm <- ggpairs(tips[,1:3])
# pm
pm <- ggpairs(tips)
# pm
pm <- ggpairs(tips, upper = "blank")
# pm
# Custom Example
pm <- ggpairs(
tips[,1:4],
upper = list(continuous = "density", combo = "box"),
lower = list(continuous = "points", combo = "dot")
)
# pm
pm
df = subset(ToothGrowth,dose ==0.5)
tres_05 <- t.test(len ~ supp,data = df, paired = FALSE, var.equal = FALSE)
tres_05
df = subset(ToothGrowth,dose == 1.0)
tres_10 <- t.test(len ~ supp,data = df, paired = FALSE, var.equal = FALSE)
tres_10
df = subset(ToothGrowth,dose == 2.0)
tres_20 <- t.test(len ~ supp,data = df, paired = FALSE, var.equal = FALSE)
tres_20
comb <- c(tres_05$value,tres_05$conf[1],tres_05$conf[2],tres_10$value,tres_10$conf[1],tres_10$conf[2],tres_20$value,tres_20$conf[1],tres_20$conf[2])
comb_m <- matrix(comb,nrow = 3)
View(comb_m)
comb <- c(tres_05$value,tres_05$conf[1],tres_05$conf[2],tres_10$value,tres_10$conf[1],tres_10$conf[2],tres_20$value,tres_20$conf[1],tres_20$conf[2])
tres_05$value,tres_05$conf[1],tres_05$conf[2]
tres_05$value
tres_10$value
comb <- c(tres_05$p.value,tres_05$conf[1],tres_05$conf[2],tres_10$p.value,tres_10$conf[1],tres_10$conf[2],tres_20$p.value,tres_20$conf[1],tres_20$conf[2])
comb_m <- matrix(comb,nrow = 3)
View(comb_m)
setwd("H:/Dropbox/CS/DataScience/PracMachine/Project")
library(Hmisc)
install.packages("Hmisc")
library(caret)
?randomForest
library(randomForest)
?randomForest
library(Hmisc)
library(caret)
library(randomForest)
library(knitr)
set.seed(1024)
setwd("H:/Dropbox/CS/DataScience/PracMachine/Project")
data_train <- read.csv("pml-training.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_test <- read.csv("pml-testing.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_train <- read.csv("pml-training.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_test <- read.csv("pml-testing.csv", na.strings= c("NA",""," ","#DIV/0!"))
inTrain <- createDataPartition(y = data_train$classe,p=0.7,list=FALSE)
training <- data_train[inTrain,]
crossValidation <- data_train[-inTrain,]
dim(training);dim(crossValidation)
model <- randomForest(classe ~., data = training)
model
data_train <- data_train[,colSums(is.na(data_train))==0]
data_test <- data_test[,colSums(is.na(data_test))==0]
inTrain <- createDataPartition(y = data_train$classe,p=0.7,list=FALSE)
training <- data_train[inTrain,]
crossValidation <- data_train[-inTrain,]
dim(training);dim(crossValidation)
model <- randomForest(classe ~., data = training)
model
pred_result <- predict(model, data_test)
data_test <- data_test[1:length(data_test)-1]
pred_result <- predict(model, data_test)
pred_result
data_test <- read.csv("pml-testing.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_test <- data_test[,colSums(is.na(data_test))==0]
data_test_n <- data_test[1:length(data_test)-1]
pred_result <- predict(model, data_test_n)
View(crossValidation)
head(data_test_n,1)
head(data_test_n,0)
head(model,0)
head(data_train,0)
```{r}
data_train <- data_train[,colSums(is.na(data_train))==0]
data_test <- data_test[,colSums(is.na(data_test))==0]
data_train <- data_train[,-c(1:7)]
data_test <- data_test[,-c(1:7)]
```
inTrain <- createDataPartition(y = data_train$classe,p=0.7,list=FALSE)
training <- data_train[inTrain,]
crossValidation <- data_train[-inTrain,]
dim(training);dim(crossValidation)
model <- randomForest(classe ~., data = training)
CroVal <- predict(model, crossValidation)
confusionMatrix(crossValidation$classe,CroVal)
data_test_n <- data_test[1:length(data_test)-1]
pred_result <- predict(model, data_test_n)
pred_result
CroVal <- predict(model, crossValidation)
library(Hmisc)
library(caret)
library(randomForest)
library(knitr)
set.seed(1024)
setwd("H:/Dropbox/CS/DataScience/PracMachine/Project")
data_train <- read.csv("pml-training.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_test <- read.csv("pml-testing.csv", na.strings= c("NA",""," ","#DIV/0!"))
data_train <- data_train[,colSums(is.na(data_train))==0]
data_test <- data_test[,colSums(is.na(data_test))==0]
data_train <- data_train[,-c(1:7)]
data_test <- data_test[,-c(1:7)]
inTrain <- createDataPartition(y = data_train$classe,p=0.7,list=FALSE)
training <- data_train[inTrain,]
crossValidation <- data_train[-inTrain,]
dim(training);dim(crossValidation)
model <- randomForest(classe ~., data = training)
model
CroVal <- predict(model, crossValidation)
confusionMatrix(crossValidation$classe,CroVal)
